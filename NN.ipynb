{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f95383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'bedrooms', 'has_photo', 'price', 'square_feet',\n",
       "       'cityname', 'state', 'latitude', 'longitude', 'time', 'pool', 'gym',\n",
       "       'parking', 'sauna', 'elevator', 'clubhouse', 'source_Andere source',\n",
       "       'source_GoSection8', 'source_ListedBuy', 'source_RealRentals',\n",
       "       'source_RentDigs.com', 'source_RentLingo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"preprocessed_apartment_rentals_no_state_dummies_nocluster.csv\")\n",
    "\n",
    "# Features und Ziel\n",
    "X = data.drop(columns=[\"price\"])\n",
    "y = data[\"price\"]\n",
    "\n",
    "# Numerische Spalten\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# Skalieren\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "X[\"state\"] = X[\"state\"].astype(\"category\")\n",
    "X[\"cityname\"] = X[\"cityname\"].astype(\"category\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc27c4",
   "metadata": {},
   "source": [
    "## ðŸ§  Hyperparameter des MLPRegressor (Neuronales Netz)\n",
    "\n",
    "Der **MLPRegressor** implementiert ein Feedforward-Neuronales Netz und ist ein komplexes nichtlineares Modell. Die Parameter definieren das Suchgitter (`mlp_params`) fÃ¼r die Optimierung der Architektur und Regulierung in der Nested Cross-Validation.\n",
    "\n",
    "| Parameter | Beschreibung | Im Code definierte Werte |\n",
    "| :--- | :--- | :--- |\n",
    "| **`hidden_layer_sizes`** | Definiert die **Architektur des Netzes**: Die Anzahl der versteckten Schichten (Hidden Layers) und die Anzahl der Neuronen pro Schicht. | `[(10, 10), (50, 50)]` |\n",
    "| **`activation`** | Die **Aktivierungsfunktion** fÃ¼r die versteckten Schichten. Definiert die NichtlinearitÃ¤t des Modells. | `[\"relu\"]` |\n",
    "| **`alpha`** | Der **L2-Regularisierungsterm** (Ã¤quivalent zu Ridge Regression). Ein hÃ¶herer Wert reduziert die KomplexitÃ¤t und hilft, **Overfitting** zu verhindern. | `np.logspace(-5, -2, 4)` |\n",
    "| **`max_iter`** | Die **maximale Anzahl von Iterationen** (Epochen), die der Optimierer Ã¼ber die Trainingsdaten ausfÃ¼hren soll. | `[500]` |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ ErlÃ¤uterung der Netzarchitektur\n",
    "\n",
    "\n",
    "\n",
    "[Image of a feedforward neural network architecture showing input, hidden, and output layers]\n",
    "\n",
    "\n",
    "* **Netzarchitektur:** `(10, 10)` bedeutet zwei versteckte Schichten mit jeweils 10 Neuronen. `(50, 50)` bedeutet zwei versteckte Schichten mit jeweils 50 Neuronen.\n",
    "* **`relu` (Rectified Linear Unit):** Sorgt dafÃ¼r, dass das Netz **NichtlinearitÃ¤ten** lernen kann (d.h. komplexere Beziehungen als eine einfache lineare Regression).\n",
    "* **`alpha` (Regularisierung):** Die Suche Ã¼ber $\\text{np.logspace}(-5, -2, 4)$ testet logarithmisch verteilte Werte zwischen $10^{-5}$ und $10^{-2}$. Dies ist entscheidend, um die ModellkomplexitÃ¤t zu kontrollieren.\n",
    "* **`max_iter`:** Da Neuronale Netze sequenziell lernen, ist ein ausreichender Wert notwendig, um die **Konvergenz** des Optimierers zu gewÃ¤hrleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36354f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte MLP Nested CV...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 4.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.4min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.2min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.7min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.1min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.7min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 1.0min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.3min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.1min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.4min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.0min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.1min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.8min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.0min\n",
      "Outer Fold 1/5 | Best Params: {'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': (50, 50), 'max_iter': 1000} | Fit Time: 163.728s | Outer RÂ²: 0.689 | MSE: 147337.391\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 5.0min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.4min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.7min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.6min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.3min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time=  52.8s\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 1.8min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.6min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.3min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 2/5 | Best Params: {'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': (50, 50), 'max_iter': 1000} | Fit Time: 246.295s | Outer RÂ²: 0.688 | MSE: 145058.973\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "from Nested_CV import NestedCVRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(10,10), (50, 50)],\n",
    "    #\"activation\": [\"relu\"],\n",
    "    #\"alpha\": np.logspace(-5, -2, 4),\n",
    "    \"max_iter\": [1000], # ErhÃ¶hen der Iterationen ist oft nÃ¶tig\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"early_stopping\": [True]\n",
    "}\n",
    "\n",
    "mlp_cv = NestedCVRegressor(MLPRegressor(random_state=42), mlp_params)\n",
    "print(\"Starte MLP Nested CV...\")\n",
    "mlp_cv.run(X, y, output=True)\n",
    "\n",
    "print(\"\\n--- MLP Ergebnisse ---\")\n",
    "print(\"MLP Mean RÂ²:\", mlp_cv.get_mean_r2())\n",
    "print(\"MLP best params:\", mlp_cv.get_best_params())\n",
    "#mlp_cv.plot_scores(\"MLP Nested CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlp_cv.get_best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "number_outer_cv_splits = 5\n",
    "model_evaluation = pd.DataFrame({\"Fold\": range(1, number_outer_cv_splits+1)})\n",
    "model_evaluation['Modell'] = ['MLP_NN'] * number_outer_cv_splits\n",
    "model_evaluation['R_2'] = mlp_cv.get_r2_scores()\n",
    "model_evaluation['MSE'] = mlp_cv.get_mse_scores()\n",
    "model_evaluation[\"runtime\"] = mlp_cv.get_fit_times()\n",
    "model_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016d396",
   "metadata": {},
   "source": [
    "# TORCH NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class TorchRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, hidden_sizes=(64, 64), lr=1e-3, epochs=50, batch_size=64, device=None):\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        layers = []\n",
    "        last = input_dim\n",
    "        for h in self.hidden_sizes:\n",
    "            layers.append(nn.Linear(last, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "        self.model = self._build_model(X.shape[1]).to(self.device)\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            for xb, yb in loader:\n",
    "                opt.zero_grad()\n",
    "                pred = self.model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        self.model.eval()\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            return self.model(X).cpu().numpy().ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114987d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Torch Nested CV...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m torch_cv = NestedCVRegressorWithTargetEncoding(TorchRegressor(), param_grid=torch_params, encode_cols=[\u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcityname\u001b[39m\u001b[33m\"\u001b[39m], outer_splits=\u001b[32m2\u001b[39m, inner_splits=\u001b[32m2\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarte Torch Nested CV...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mtorch_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Torch NN Ergebnisse ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMean RÂ²:\u001b[39m\u001b[33m\"\u001b[39m, torch_cv.get_mean_r2())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Git\\DataProject-WS-25-26\\Nested_CV_targetEncoding.py:70\u001b[39m, in \u001b[36mNestedCVRegressorWithTargetEncoding.run\u001b[39m\u001b[34m(self, X, y, output)\u001b[39m\n\u001b[32m     60\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     61\u001b[39m     estimator=pipe,\n\u001b[32m     62\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     verbose=\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     67\u001b[39m )\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Inner CV + Hyperparameter tuning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m best_params = grid_search.best_params_\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params.append(best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1017\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1018\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1019\u001b[39m     )\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1027\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1569\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1570\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    962\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    965\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    966\u001b[39m         )\n\u001b[32m    967\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    989\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from Nested_CV_targetEncoding import NestedCVRegressorWithTargetEncoding\n",
    "\n",
    "torch_params = {\n",
    "    \"hidden_sizes\": [(32,32), (64,64)],\n",
    "    \"epochs\": [500],\n",
    "    \"batch_size\": [32],\n",
    "    #\"lr\": [1e-3],\n",
    "}\n",
    "\n",
    "torch_cv = NestedCVRegressorWithTargetEncoding(TorchRegressor(), param_grid=torch_params, encode_cols=[\"state\", \"cityname\"], outer_splits=2, inner_splits=2)\n",
    "\n",
    "print(\"Starte Torch Nested CV...\")\n",
    "torch_cv.run(X, y, output=True)\n",
    "\n",
    "print(\"\\n--- Torch NN Ergebnisse ---\")\n",
    "print(\"Mean RÂ²:\", torch_cv.get_mean_r2())\n",
    "print(\"Best params:\", torch_cv.get_best_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03123c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "number_outer_cv_splits = 5\n",
    "model_evaluation = pd.DataFrame({\"Fold\": range(1, number_outer_cv_splits+1)})\n",
    "model_evaluation['Modell'] = ['Torch_NN'] * number_outer_cv_splits\n",
    "model_evaluation['R_2'] = torch_cv.get_r2_scores()\n",
    "model_evaluation['MSE'] = torch_cv.get_mse_scores()\n",
    "model_evaluation[\"runtime\"] = torch_cv.get_fit_times()\n",
    "model_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
