{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f95383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bathrooms', 'bedrooms', 'has_photo', 'square_feet', 'latitude',\n",
      "       'longitude', 'time', 'pool', 'gym', 'parking', 'sauna', 'elevator',\n",
      "       'clubhouse', 'source_Andere source', 'source_GoSection8',\n",
      "       'source_ListedBuy', 'source_RealRentals', 'source_RentDigs.com',\n",
      "       'source_RentLingo', 'state_AK', 'state_AL', 'state_AR', 'state_AZ',\n",
      "       'state_CA', 'state_CO', 'state_CT', 'state_DC', 'state_DE', 'state_FL',\n",
      "       'state_GA', 'state_HI', 'state_IA', 'state_ID', 'state_IL', 'state_IN',\n",
      "       'state_KS', 'state_KY', 'state_LA', 'state_MA', 'state_MD', 'state_ME',\n",
      "       'state_MI', 'state_MN', 'state_MO', 'state_MS', 'state_MT', 'state_NC',\n",
      "       'state_ND', 'state_NE', 'state_NH', 'state_NJ', 'state_NM', 'state_NV',\n",
      "       'state_NY', 'state_OH', 'state_OK', 'state_OR', 'state_PA', 'state_RI',\n",
      "       'state_SC', 'state_SD', 'state_TN', 'state_TX', 'state_UT', 'state_VA',\n",
      "       'state_VT', 'state_WA', 'state_WI', 'state_WV', 'state_WY', 'cluster_0',\n",
      "       'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5',\n",
      "       'cluster_6', 'cluster_7', 'cluster_8', 'cluster_9', 'cluster_10',\n",
      "       'cluster_11', 'cluster_12', 'cluster_13', 'cluster_14', 'cluster_15',\n",
      "       'cluster_16', 'cluster_17', 'cluster_18', 'cluster_19'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"preprocessed_apartment_rentals_clusters.csv\")\n",
    "# Beispiel-Daten (ersetze X, y durch deine Daten)\n",
    "features = data.drop(columns=[\"price\", \"cityname\", \"state\"]).columns\n",
    "print(features)\n",
    "X, y = data.drop(columns=[\"price\", \"cityname\", \"state\"]).values, data[\"price\"].values\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc27c4",
   "metadata": {},
   "source": [
    "## ðŸ§  Hyperparameter des MLPRegressor (Neuronales Netz)\n",
    "\n",
    "Der **MLPRegressor** implementiert ein Feedforward-Neuronales Netz und ist ein komplexes nichtlineares Modell. Die Parameter definieren das Suchgitter (`mlp_params`) fÃ¼r die Optimierung der Architektur und Regulierung in der Nested Cross-Validation.\n",
    "\n",
    "| Parameter | Beschreibung | Im Code definierte Werte |\n",
    "| :--- | :--- | :--- |\n",
    "| **`hidden_layer_sizes`** | Definiert die **Architektur des Netzes**: Die Anzahl der versteckten Schichten (Hidden Layers) und die Anzahl der Neuronen pro Schicht. | `[(10, 10), (50, 50)]` |\n",
    "| **`activation`** | Die **Aktivierungsfunktion** fÃ¼r die versteckten Schichten. Definiert die NichtlinearitÃ¤t des Modells. | `[\"relu\"]` |\n",
    "| **`alpha`** | Der **L2-Regularisierungsterm** (Ã¤quivalent zu Ridge Regression). Ein hÃ¶herer Wert reduziert die KomplexitÃ¤t und hilft, **Overfitting** zu verhindern. | `np.logspace(-5, -2, 4)` |\n",
    "| **`max_iter`** | Die **maximale Anzahl von Iterationen** (Epochen), die der Optimierer Ã¼ber die Trainingsdaten ausfÃ¼hren soll. | `[500]` |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ ErlÃ¤uterung der Netzarchitektur\n",
    "\n",
    "\n",
    "\n",
    "[Image of a feedforward neural network architecture showing input, hidden, and output layers]\n",
    "\n",
    "\n",
    "* **Netzarchitektur:** `(10, 10)` bedeutet zwei versteckte Schichten mit jeweils 10 Neuronen. `(50, 50)` bedeutet zwei versteckte Schichten mit jeweils 50 Neuronen.\n",
    "* **`relu` (Rectified Linear Unit):** Sorgt dafÃ¼r, dass das Netz **NichtlinearitÃ¤ten** lernen kann (d.h. komplexere Beziehungen als eine einfache lineare Regression).\n",
    "* **`alpha` (Regularisierung):** Die Suche Ã¼ber $\\text{np.logspace}(-5, -2, 4)$ testet logarithmisch verteilte Werte zwischen $10^{-5}$ und $10^{-2}$. Dies ist entscheidend, um die ModellkomplexitÃ¤t zu kontrollieren.\n",
    "* **`max_iter`:** Da Neuronale Netze sequenziell lernen, ist ein ausreichender Wert notwendig, um die **Konvergenz** des Optimierers zu gewÃ¤hrleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36354f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte MLP Nested CV...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 4.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.4min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.2min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.8min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.7min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.1min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.7min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 1.0min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.3min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.1min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.4min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.0min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.1min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.8min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.0min\n",
      "Outer Fold 1/5 | Best Params: {'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': (50, 50), 'max_iter': 1000} | Fit Time: 163.728s | Outer RÂ²: 0.689 | MSE: 147337.391\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 5.0min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.4min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 3.7min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.6min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 4.3min\n",
      "[CV] END batch_size=16, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time=  52.8s\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 1.8min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(10, 10), max_iter=1000; total time= 2.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.6min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 3.9min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.3min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 1.5min\n",
      "[CV] END batch_size=32, early_stopping=True, hidden_layer_sizes=(50, 50), max_iter=1000; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 2/5 | Best Params: {'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': (50, 50), 'max_iter': 1000} | Fit Time: 246.295s | Outer RÂ²: 0.688 | MSE: 145058.973\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "from Nested_CV import NestedCVRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(10,10), (50, 50)],\n",
    "    #\"activation\": [\"relu\"],\n",
    "    #\"alpha\": np.logspace(-5, -2, 4),\n",
    "    \"max_iter\": [1000], # ErhÃ¶hen der Iterationen ist oft nÃ¶tig\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"early_stopping\": [True]\n",
    "}\n",
    "\n",
    "mlp_cv = NestedCVRegressor(MLPRegressor(random_state=42), mlp_params)\n",
    "print(\"Starte MLP Nested CV...\")\n",
    "mlp_cv.run(X, y, output=True)\n",
    "\n",
    "print(\"\\n--- MLP Ergebnisse ---\")\n",
    "print(\"MLP Mean RÂ²:\", mlp_cv.get_mean_r2())\n",
    "print(\"MLP best params:\", mlp_cv.get_best_params())\n",
    "#mlp_cv.plot_scores(\"MLP Nested CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlp_cv.get_best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "number_outer_cv_splits = 5\n",
    "model_evaluation = pd.DataFrame({\"Fold\": range(1, number_outer_cv_splits+1)})\n",
    "model_evaluation['Modell'] = ['MLP_NN'] * number_outer_cv_splits\n",
    "model_evaluation['R_2'] = mlp_cv.get_r2_scores()\n",
    "model_evaluation['MSE'] = mlp_cv.get_mse_scores()\n",
    "model_evaluation[\"runtime\"] = mlp_cv.get_fit_times()\n",
    "model_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016d396",
   "metadata": {},
   "source": [
    "# TORCH NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class TorchRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, hidden_sizes=(64, 64), lr=1e-3, epochs=50, batch_size=64, device=None):\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        layers = []\n",
    "        last = input_dim\n",
    "        for h in self.hidden_sizes:\n",
    "            layers.append(nn.Linear(last, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "\n",
    "        self.model = self._build_model(X.shape[1]).to(self.device)\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            for xb, yb in loader:\n",
    "                opt.zero_grad()\n",
    "                pred = self.model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            return self.model(X).cpu().numpy().ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114987d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Torch Nested CV...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.1min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.0min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.0min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.0min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 2.9min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 3.2min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 3.2min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 3.2min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 3.2min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 3.2min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 1.9min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 1.8min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 1.9min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 1.9min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 2.0min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 1.9min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 2.0min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 1.9min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 2.1min\n",
      "[CV] END batch_size=64, epochs=50, hidden_sizes=(64, 64), lr=0.001; total time= 2.0min\n",
      "Outer Fold 1/5 | Best Params: {'batch_size': 32, 'epochs': 50, 'hidden_sizes': (64, 64), 'lr': 0.001} | Fit Time: 238.747s | Outer RÂ²: 0.684 | MSE: 149629.034\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.0min\n",
      "[CV] END batch_size=32, epochs=50, hidden_sizes=(32, 32), lr=0.001; total time= 3.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m torch_cv = NestedCVRegressor(TorchRegressor(), torch_params)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarte Torch Nested CV...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mtorch_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Torch NN Ergebnisse ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMean RÂ²:\u001b[39m\u001b[33m\"\u001b[39m, torch_cv.get_mean_r2())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Git\\DataProject-WS-25-26\\Nested_CV.py:54\u001b[39m, in \u001b[36mNestedCVRegressor.run\u001b[39m\u001b[34m(self, X, y, output)\u001b[39m\n\u001b[32m     51\u001b[39m y_train, y_test = y[train_ix], y[test_ix]\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Inner CV + hyperparameter tuning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# beste hyperparameter sichern\u001b[39;00m\n\u001b[32m     57\u001b[39m best_params = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1017\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1018\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1019\u001b[39m     )\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1027\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1569\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1570\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    962\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    965\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    966\u001b[39m         )\n\u001b[32m    967\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    989\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mTorchRegressor.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     38\u001b[39m     opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     loss = loss_fn(pred, yb)\n\u001b[32m     41\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from Nested_CV import NestedCVRegressor\n",
    "\n",
    "torch_params = {\n",
    "    \"hidden_sizes\": [(32,32), (64,64)],\n",
    "    \"epochs\": [50],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"lr\": [1e-3]\n",
    "}\n",
    "\n",
    "torch_cv = NestedCVRegressor(TorchRegressor(), torch_params)\n",
    "\n",
    "print(\"Starte Torch Nested CV...\")\n",
    "torch_cv.run(X, y, output=True)\n",
    "\n",
    "print(\"\\n--- Torch NN Ergebnisse ---\")\n",
    "print(\"Mean RÂ²:\", torch_cv.get_mean_r2())\n",
    "print(\"Best params:\", torch_cv.get_best_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03123c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "number_outer_cv_splits = 5\n",
    "model_evaluation = pd.DataFrame({\"Fold\": range(1, number_outer_cv_splits+1)})\n",
    "model_evaluation['Modell'] = ['Torch_NN'] * number_outer_cv_splits\n",
    "model_evaluation['R_2'] = torch_cv.get_r2_scores()\n",
    "model_evaluation['MSE'] = torch_cv.get_mse_scores()\n",
    "model_evaluation[\"runtime\"] = torch_cv.get_fit_times()\n",
    "model_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
