{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32de42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bathrooms', 'bedrooms', 'has_photo', 'square_feet', 'latitude',\n",
      "       'longitude', 'time', 'pool', 'gym', 'parking', 'sauna', 'elevator',\n",
      "       'clubhouse', 'source_Andere source', 'source_GoSection8',\n",
      "       'source_ListedBuy', 'source_RealRentals', 'source_RentDigs.com',\n",
      "       'source_RentLingo', 'state_AK', 'state_AL', 'state_AR', 'state_AZ',\n",
      "       'state_CA', 'state_CO', 'state_CT', 'state_DC', 'state_DE', 'state_FL',\n",
      "       'state_GA', 'state_HI', 'state_IA', 'state_ID', 'state_IL', 'state_IN',\n",
      "       'state_KS', 'state_KY', 'state_LA', 'state_MA', 'state_MD', 'state_ME',\n",
      "       'state_MI', 'state_MN', 'state_MO', 'state_MS', 'state_MT', 'state_NC',\n",
      "       'state_ND', 'state_NE', 'state_NH', 'state_NJ', 'state_NM', 'state_NV',\n",
      "       'state_NY', 'state_OH', 'state_OK', 'state_OR', 'state_PA', 'state_RI',\n",
      "       'state_SC', 'state_SD', 'state_TN', 'state_TX', 'state_UT', 'state_VA',\n",
      "       'state_VT', 'state_WA', 'state_WI', 'state_WV', 'state_WY', 'cluster_0',\n",
      "       'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5',\n",
      "       'cluster_6', 'cluster_7', 'cluster_8', 'cluster_9', 'cluster_10',\n",
      "       'cluster_11', 'cluster_12', 'cluster_13', 'cluster_14', 'cluster_15',\n",
      "       'cluster_16', 'cluster_17', 'cluster_18', 'cluster_19'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"preprocessed_apartment_rentals_clusters.csv\")\n",
    "# Beispiel-Daten (ersetze X, y durch deine Daten)\n",
    "features = data.drop(columns=[\"price\", \"cityname\", \"state\"]).columns\n",
    "print(features)\n",
    "X, y = data.drop(columns=[\"price\", \"cityname\", \"state\"]).values, data[\"price\"].values\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8c15c",
   "metadata": {},
   "source": [
    "## üöÄ Hyperparameter des GradientBoostingRegressor\n",
    "\n",
    "Der **Gradient Boosting Regressor (GBR)** ist eine **sequenzielle Ensemble-Methode**, die schwache Modelle (typischerweise Entscheidungsb√§ume) iterativ kombiniert. Die Parameter definieren das Suchgitter (`gbr_params`) f√ºr die Optimierung in der Nested Cross-Validation.\n",
    "\n",
    "| Parameter | Beschreibung | Im Code definierte Werte |\n",
    "| :--- | :--- | :--- |\n",
    "| **`n_estimators`** | Die **Anzahl der Boosting-Stufen** (Anzahl der sequenziell hinzugef√ºgten schwachen Lerner, d.h. B√§ume). | `[5, 50]` |\n",
    "| **`learning_rate`** | Die **Schrumpfungsrate** ($\\eta$). Skaliert den Beitrag jedes Baumes. Ein kleinerer Wert erfordert mehr `n_estimators`, verbessert aber oft die Generalisierung. | `[0.1, 0.2]` |\n",
    "| **`max_depth`** | Die **maximale Tiefe** jedes einzelnen Entscheidungsbaums (des *schwachen Lerners*). GBR verwendet meist flache B√§ume (z.B. Tiefe 3-5). | `[3, 5, 7]` |\n",
    "| **`min_samples_split`** | Die **minimale Anzahl von Datenpunkten** in einem internen Knoten, die f√ºr eine Teilung erforderlich ist. Dient zur Kontrolle der Baumkomplexit√§t. | `[5, 10]` |\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Erl√§uterung der Boosting-Strategie\n",
    "\n",
    "\n",
    "\n",
    "Gradient Boosting arbeitet, indem es sequentielle B√§ume aufbaut, wobei jeder neue Baum versucht, die **Restfehler** (Residuen) des vorherigen Ensembles zu korrigieren.\n",
    "\n",
    "1.  **`n_estimators`** und **`learning_rate`** steuern zusammen die **Gesamtst√§rke** des Modells und die Geschwindigkeit des Lernprozesses.\n",
    "2.  **`max_depth`** und **`min_samples_split`** steuern die **Komplexit√§t** jedes einzelnen, schwachen Entscheidungsbaums, der zur Korrektur der Residuen verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nested_CV import NestedCVRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr_params = {\n",
    "    \"n_estimators\": [5,20],\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"min_samples_split\": [5, 10]\n",
    "}\n",
    "\n",
    "gbr_cv = NestedCVRegressor(GradientBoostingRegressor(random_state=42), gbr_params)\n",
    "print(\"\\nStarte Gradient Boosting Nested CV...\")\n",
    "gbr_cv.run(X, y, output=True)\n",
    "\n",
    "gbr_cv.plot_scores(\"Gradient Boosting Nested CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff502022",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outer_cv_splits = 5\n",
    "model_evaluation = pd.DataFrame({\"Fold\": range(1, number_outer_cv_splits+1)})\n",
    "model_evaluation['Modell'] = ['Ridge'] * number_outer_cv_splits\n",
    "model_evaluation['R_2'] = gbr_cv.get_r2_scores()\n",
    "model_evaluation['MSE'] = gbr_cv.get_mse_scores()\n",
    "model_evaluation[\"runtime\"] = gbr_cv.get_fit_times()\n",
    "model_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
